import requests
import json
import re
from rapidfuzz import process, fuzz
import nltk
from nltk.corpus import words
import time
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

# ğŸ”¹ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ñ… ÑĞ»Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ
nltk.download("words", quiet=True)
nltk.download("wordnet", quiet=True)
nltk.download("omw-1.4", quiet=True)

english_words = set(words.words())

# ğŸ”¹ Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ ÑĞ»ĞµĞ½Ğ³Ğ° (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ)
slang_words = {
    # Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾-ÑĞ»ĞµĞ½Ğ³
    "gm", "gn", "rekt", "pamp", "dump", "moon", "lambo", "hodl", "fomo", "jomo",
    "ngmi", "wagmi", "btd", "btdi", "btfd", "ape", "apestrong", "shill", "rug",
    "rugged", "rugpull", "bagholder", "bags", "degen", "paperhands", "diamondhands",
    "whale", "shrimp", "pleb", "sat", "sats", "stacking", "stackingsats", "alpha",
    "beta", "gigachad", "plebs", "autist", "autistic", "ser", "frens", "wagie",
    "anon", "broski", "chad", "giga", "apeing", "apes", "cope", "copeium", "copium",
    "hopium", "moonbois", "moonboy", "moonboys", "lasereyes", 'virtual', 'memecoins',

    # Ñ‚Ğ¸ĞºĞµÑ€Ñ‹ Ğ¸ Ğ°Ğ±Ğ±Ñ€ĞµĞ²Ğ¸Ğ°Ñ‚ÑƒÑ€Ñ‹
     "wojak", "memecoin", "alts", "alt",

    # Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    "long", "short", "pump", "dump", "flippening", "alltimehigh", "ath", "dip",
    "buythedip", "sellthetop", "moonshot", "parabolic", "gigapump", "gigadump",
    "bottom", "top", "bullrun", "bearrun", "capitulation", "deadcat", "doubletop",
    "doublebottom", "rangebound", "sideways", "exitliquidity", "bagging",

    # NFT / Web3
    "floor", "mint", "minted", "airdrop", "drop", "gmers", "degenmint", "delist",
    "delisted", "flooring", "sweep", "sweeping", "wagmiarmy", "metaverse",
    "metaversebro", "pfp", "pfps", "jpeg", "jpegs", "rightclicksave", "opensea",
    "blur", "rarible", "magiceden", "onchain", "offchain", "dao", "defi",
    "shitcoin", "shitcoins", "shitcoiner", "tokenomics", "ponzinomics",

    # ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¼ĞµĞ¼Ñ‹
    "lol", "lmao", "rofl", "kek", "xd", "vibe", "sus", "yeet", "bruh", "pog",
    "poggers", "smh", "idk", "irl", "afk", "imo", "imho", "geez", "noob", "ezpz",
    "wheee", "stonks", "stonk", "tendies", "yolo", "apein", "apeout", "fud",
    "fudding", "based", "cringe", "vibin", "glhf", "pwned", "owned", "clown",
    "clownworld", "sadge", "monkaS", "peepo", "omegalul", "lulw", "lul", "5head",
    "galaxybrain", "npc", "seethe", "kekw", "xdd", "gigachad", "soyboy", "simp",
    "doomer", "bloomer", "coomer", "boomer", "zoomer", "sigma", "betaorbiter",
    "topg", "gyatt",

    # Ğ¿Ñ€Ğ¾Ñ‡ĞµĞµ ÑĞµÑ‚ĞµĞ²Ğ¾Ğµ
    "np", "idc", "ffs", "omg", "wtf", "gg", "ez", "wp", "lfg", "goat", "mfers",
    "toobased", "vitalik", "satoshi", "elon", "cz", "bro", "bros", "fam", "irlbro",
    "basedgod", "shitpost", "shitposter", "shitposting", "okboomer", "okzoomers",
    "degens", "gigabrain", "megalul", "bigbrain", "smartmoney", "newbie", "pajeet",
    "wagmiarmy", "anonarmy", "pumpndump", "insiders", "apestrong", "hodler",
    "cryptobros", "cryptobro", "moonmission", "diamondhanded", "paperhanded", "nft"
}

extended_slang = slang_words | {w + "s" for w in slang_words}

def is_english_word(word: str) -> bool:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¼:
    1) Ğ•ÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¾Ğ½Ğ¾ Ğ² nltk.corpus.words
    2) Ğ•ÑÑ‚ÑŒ Ğ»Ğ¸ Ğ´Ğ»Ñ Ğ½ĞµĞ³Ğ¾ Ñ…Ğ¾Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ synset Ğ² WordNet
    """
    if word in english_words:
        return True
    if wordnet.synsets(word):  # ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑĞ¸Ğ½Ğ¾Ğ½Ğ¸Ğ¼Ñ‹ Ğ² wordnet
        return True
    return False

def fetch_top_coins_with_pairs(output_path="tickers_pairs.json",
                               min_market_cap=20_000_000,
                               min_volume=1000,
                               max_pages=10):
    """
    Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹ Ñ CoinGecko, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾ ĞºĞ°Ğ¿Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±ÑŠĞµĞ¼Ñƒ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²,
    Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¿Ğ°Ñ€Ñ‹ Ñ‚Ğ¸ĞºĞµÑ€ -> Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ² JSON.
    Ğ¡ Ğ»Ğ¾Ğ³Ğ°Ğ¼Ğ¸: ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğµ API.
    """
    import time, requests, json, re

    url = "https://api.coingecko.com/api/v3/coins/markets"
    params = {"vs_currency": "usd", "order": "market_cap_desc", "per_page": 250, "page": 1}

    ticker_name_pairs = dict()
    pattern = re.compile(r"^[a-z0-9]+$")

    while params["page"] <= max_pages:
        print(f"ğŸ”¹ ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ {params['page']}...")
        for attempt in range(5):
            try:
                response = requests.get(url, params=params)
                if response.status_code == 429:  # Too Many Requests
                    wait_time = 10 * (attempt + 1)
                    print(f"âš ï¸ Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ API, Ğ¶Ğ´Ñ‘Ğ¼ {wait_time} ÑĞµĞº...")
                    time.sleep(wait_time)
                    continue
                response.raise_for_status()
                break
            except requests.exceptions.HTTPError as e:
                wait_time = 5
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° {e}, Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ Ñ‡ĞµÑ€ĞµĞ· {wait_time} ÑĞµĞº...")
                time.sleep(wait_time)
        else:
            print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼")
            break

        data = response.json()
        if not data:
            print("âš ï¸ ĞŸÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°, Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼")
            break

        new_pairs = 0
        for coin in data:
            market_cap = coin.get("market_cap") or 0
            volume = coin.get("total_volume") or 0
            if market_cap >= min_market_cap and volume >= min_volume:
                name = coin["name"].lower().replace(" ", "")
                symbol = coin["symbol"].lower()
                if 2 <= len(symbol) <= 10 and pattern.match(symbol):
                    if symbol not in ticker_name_pairs:
                        ticker_name_pairs[symbol] = name
                        new_pairs += 1

        print(f"âœ… Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° {params['page']} Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ°, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {new_pairs} Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ°Ñ€, Ğ²ÑĞµĞ³Ğ¾ {len(ticker_name_pairs)}")
        params["page"] += 1
        time.sleep(1)  # Ğ¿Ğ°ÑƒĞ·Ğ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ ÑĞ»Ğ¾Ğ²Ğ¸Ñ‚ÑŒ 429

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(ticker_name_pairs, f, ensure_ascii=False, indent=2)

    print(f"ğŸ‰ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ {len(ticker_name_pairs)} Ğ¿Ğ°Ñ€ Ñ‚Ğ¸ĞºĞµÑ€->Ğ¸Ğ¼Ñ Ğ² {output_path}")


lemmatizer = WordNetLemmatizer()

def find_crypto_mentions_v2(text, ticker_name_pairs, threshold=85):
    text = text.lower()
    words_in_text = re.findall(r"[a-zA-Z0-9$]+", text)

    matches = set()
    tickers = list(ticker_name_pairs.keys())
    names = list(ticker_name_pairs.values())

    for word in words_in_text:
        if len(word) < 2:
            continue

        lemma = lemmatizer.lemmatize(word, wordnet.NOUN)
        lemma = lemmatizer.lemmatize(lemma, wordnet.VERB)

        if is_english_word(lemma):
            continue
        if word in extended_slang or lemma in extended_slang:
            continue

        # ğŸ”¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ Ñ‚Ğ¸ĞºĞµÑ€Ğ¾Ğ¼
        if word in tickers:
            matches.add(word)
            continue

        # ğŸ”¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼
        if word in names:
            # Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğ¸ĞºĞµÑ€
            ticker = [t for t, n in ticker_name_pairs.items() if n == word][0]
            matches.add(ticker)
            continue

        # ğŸ”¹ fuzzy Ñ‚Ğ¸ĞºĞµÑ€
        result = process.extractOne(word, tickers, scorer=fuzz.ratio, score_cutoff=threshold)
        if result:
            candidate, score, _ = result
            if score >= 80 and (len(word) >= 4 or score > 92):
                matches.add(candidate)
                continue

        # ğŸ”¹ fuzzy Ğ¸Ğ¼Ñ
        result = process.extractOne(word, names, scorer=fuzz.ratio, score_cutoff=threshold)
        if result:
            candidate_name, score, _ = result
            if score >= 80 and (len(word) >= 4 or score > 92):
                ticker = [t for t, n in ticker_name_pairs.items() if n == candidate_name][0]
                matches.add(ticker)

    matches = {m for m in matches if m not in slang_words}
    return sorted(matches)

# --- ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ ---
fetch_top_coins_with_pairs("clean_names_and_symbols.json")

with open("clean_names_and_symbols.json", "r", encoding="utf-8") as f:
    tickers = json.load(f)

text = """Brooo frens, last night $BTC did some giga-wick sh*t â€” candle went full âœˆï¸ then insta-dumped, ngl my stop got rekted hard af ğŸ’€.  
Meanwhile ethreum (ETHh, eeth) gas still ridic, ppl saying â€œL2s fix thisâ€, but zk-rollp testnet rugged again lmao.  
Some anon shilln SOLnaa (aka $SOL) claiming â€œhyperdrive subnetz online soonâ€, but network went kaput AGAIN, validators crying on X (ex-Twitter ğŸ¤¡).  

Bruh polkad0t fam still chanting parachain mantra since 2020, but chart = ğŸª¦. Cardaaano maxis screaming â€œCharles = Satoshiâ€ ğŸ¤¯, but ada price = sideways crab walk ğŸ¦€.  
DOGEE and shiebha memelords raiding TikTok comments, normies FOMO into $INU derivatives (floppaInu, babyShibX, shibariooo) â€” pure ponzi-nomics.  
My fren YOLOâ€™d into arbitrrum (arbz), opmtmism (oppp), zkSnyc (yes spelled like that ğŸ¤£), claiming â€œnext ETH killer bro frfrâ€, but itâ€™s just bridge exploits & farm dumpers.  

Saw whale addys moving giga bags: $ETH to CEX, $USDT to Tron chain, some shady zkBob bridge, ngmi vibes.  
CT (crypto Twitter) screaming about pepe v2, wojackX, gme-moon, and giga-sussy memecoins like $KAREN2.0, $BROKEAF, $CLOWNPEPE ğŸ¤¡.  
Even rugdevs dropping new pump-n-dumps: elonnInuuuu, xShrek, mcdoge420, gigaFLOP â€” ppl apinâ€™ like brainless bots ğŸ¤–.  

Meanwhile $BNB maxis copin â€œCZ strongâ€, but Binance FUD trending daily. FTX ghost memez â€” ppl still posting â€œSBF speedrun jail any%â€ ğŸ˜‚.  
XRP army still in cope mode: â€œsettlement tmrrw bros!!â€ â€” been sayinâ€™ this since 2017 lmao.  
Litec0in cultists say halving = moon ğŸš€, but chart = giga meh. Tron (TRXx) shills push â€œSunâ€™s planâ€ every week, no devs, only hype.  

Some weird alpha droppin on Discord: â€œVirtualzz DAOâ€ + â€œMetaApesChainâ€ legit 100x vibesâ€¦ until u read contract: owner = 1 wallet kek.  
Others pushing zkPonzi, DeFi rugs, ppl still farming â€œyieldâ€ on chains no one heard of: futrcashX, safemoonV3, rugSwap, frogDEX.  
Nft bros crying: floor bleed out, ape jpegs = dust, ppl postin gm ser with giga cope ğŸ¥².  

Honestly chartz lookin giga-sus, volume ded, liquidity poolz empty.  
Ppl yelling â€œWAGMIâ€ but whales unload quietlyâ€¦ not fin adv, just vibes.  
Bruh ngmi if u still ape top tick on memecoins spelled with 5 typos ğŸ’€.

"""
mentions = find_crypto_mentions_v2(text, tickers)
print(mentions)